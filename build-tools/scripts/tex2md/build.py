# build.py
#
# PURPOSE
#
# This script orchestrates the conversion of Agda source files (plain .agda
# and LaTeX-based literate .lagda) into Markdown-based literate Agda files
# and integration of these with manually maintained Markdown documents.
# The script also assembles the complete source structure for both mkdocs
# and mdbook web sites.
#
# KEY FEATURES
#
# Guidance on manual overrides and custom configurations for contributors.
#
# 1.  **Persistent, Manually-Refined Literate Agda Files (`.lagda.md`)**
#
#     +  **Location**. `src/` and subdirectories thereof;
#        e.g., `src/Module/File.lagda.md`.
#     +  **Behavior**.  During the build, these files are copied into
#        `_build/agda_snapshot_src/`.  If a file already has the `.lagda.md`
#        extension, this (possibly manually refined version) takes precedence over
#        a version that would otherwise be generated from the original Agda source.
#     +  **Use Case**.  Applying extensive manual edits, corrections, or custom
#        Markdown content to literate Agda files that should persist across builds.
#
# 2.  **Static Site Content (Standard Markdown `.md` files, `mkdocs.yml` base)**
#
#     +  **Location**.
#
#        +  **mkdocs**.  Place the base `mkdocs.yml` and static Markdown files
#           (plus any other static assets like images) in subdirectories of
#           `build-tools/static/mkdocs/src/`; e.g., static pages
#           go into `build-tools/static/mkdocs/src/docs/`.
#
#        +  **mdbook**.  Place the base `book.toml` and static Markdown files
#           (plus any other static assets like images) in subdirectories of
#           `build-tools/static/mdbook/`; e.g., static pages
#           go into `build-tools/static/mdbook/src/`.
#
#     +  **Behavior**.  At start of build, *all contents* of
#        `build-tools/static/mkdocs/src/` (resp.,
#        `build-tools/static/mdbook`) are copied into
#        `_build/website/mkdocs/src/` (resp., `_build/website/mdbook`) to serve
#        as the initial web site content.  Generated files (e.g., from Agda) will
#        be added to this structure. If a generated file has the same path and
#        name as a file from this static template, the generated version will
#        overwrite the static one, and a warning will be logged.
#
#     +  **Use Case**.  "About" pages, installation guides, `mkdocs.yml` (resp.,
#        `book.toml`) "template" file, images, or any documentation not derived
#        from Agda code.
#
# 3.  **Custom MkDocs Navigation (`nav.yml`)**
#
#     +  **Location**.  `build-tools/static/mkdocs/nav.yml`
#
#     +  **Behavior**.  This static file, if it exists and is valid YAML, is used
#        for the mkdocs site navigation scheme (i.e., the `nav` section of
#        `_build/website/mkdocs/src/mkdocs.yml`).  This overrides any navigation
#        structure that would otherwise be automatically generated by the build
#        script based on file names.
#
#     **Custom mdbook Navigation (`SUMMARY.md`)**
#
#     +  **Location**.  `build-tools/static/mdbook/src/SUMMARY.md`.
#
#     +  **Behavior**.  This file, if it exists, is used for the mdbook site
#        navigation scheme.
#
#     +  **Use Case**.  Provides complete, explicit control over the site's
#        navigation hierarchy and page titles in the navigation.
#
#
# PROCESS OVERVIEW
#
# In this section `m?????` refers to either `mkdocs` or `mdbook`.  Where they differ,
# instructions for mkdocs are given followed by the analog for mdbook in parentheses.
#
# 1.  Initial Site Structure Setup:
#
#     a.  Cleans and recreates necessary subdirectories within `_build/website/m?????/`
#
#     b.  The entire contents of `build-tools/static/m?????/`
#         which should include a base `mkdocs.yml` (resp., `book.toml`) and any
#         static `src/docs/` (resp., `src/`) content is copied to
#         `_build/website/m?????/` to form the initial site structure.
#
#     c.  Generates `_build/website/macros.json` from
#         `build-tools/static/latex/macros.sty` for use in LaTeX-to-Markdown
#         conversion steps.
#
# 2.  Agda Source Snapshot Preparation (`_build/agda_snapshot_src/`):
#
#     a.  Copies the entire `src/` directory (containing original Agda sources)
#         to the `_build/agda_snapshot_src/` directory.
#
#     b.  Converts any plain `.agda` files within this snapshot to `.lagda.md` format
#         and updates them in place.
#
#     c.  Process each LaTeX-based literate Agda (`.lagda`) file in `src/`
#         (by multi-stage pipeline: custom Python preprocessing -> Pandoc with Lua
#         filter -> custom Python postprocessing) to convert it into a Markdown-based
#         literate Agda (`.lagda.md`) file and place the result in
#         `_build/agda_snapshot_src/`.
#
#     d.  Result: `_build/agda_snapshot_src/` now contains all project
#         modules as `.lagda.md` files (derived from existing `.agda` or `.lagda.md`
#         files, or created from `.lagda` files processed by the tex2md pipeline,
#         maintaining the original `src/` directory structure.
#
#     NOTE files in `_build/agda_snapshot_src/` are the final `.lagda.md` files
#          comprising the new, markdown-based literate Agda source code; they can
#          be type-checking by Agda or used as input to the `agda --html` command
#          for html code-highlighting for web page generation.
#
# 3.  Site Content Generation & Population
#
#     This step adds Agda-derived content to the `_build/website/mkdocs/src/docs/`
#     (resp., `_build/website/mdbook/src`) directory, which may already contain
#     some static files from Step 1.b.)
#
#     a.  If the `--run-agda` flag is passed, `agda --html` is run on the main
#         `.lagda.md` file within `_build/agda_snapshot_src/`, with output set to
#         `_build/agda-docs/`.  Output filenames are typically flat, dot-separated
#         module names (e.g., `Ledger.Transaction.md`).
#
#     b.  If `--run-agda` is NOT passed (or if Agda processing fails), each
#         `.lagda.md` file from `_build/agda_snapshot_src/` is copied to
#         `_build/agda-docs/` and renamed to have flat, dot-separated names
#         (e.g., `Ledger.Transaction.md`).
#
# 4.  Site Finalization: `_build/website/mkdocs/src/` and `_build/website/mdbook/`
#
#     a. Static assets needed by the site (e.g., `Agda.css` if Agda HTML
#        was run, custom project CSS/JS) are copied into the appropriate
#        subdirectories of `_build/website/mkdocs/src/docs/` and/or
#        `_build/website/mdbook/src/`.
#
#     b. Files in `_build/agda-docs/` (processed by Agda to format the code blocks)
#        are copied into `_build/mkdocs/src/docs/` *and* into `_build/mdbook/src/`.
#        The `_build/mkdocs/src/mkdocs.yml`  and `_build/mdbook/book.toml` files are
#        updated:
#
#        1.  Dynamically required `extra_css` and `extra_javascript` (like
#            `Agda.css`) are added if not already present.
#
#        2.  If `mkdocs/nav.yml` exists and is valid,
#            its content is used for the `nav:` section of `mkdocs.yml`.
#
#        3.  Otherwise, the `nav` section is automatically generated by parsing
#            the `.md` filenames in `_build/mkdocs/src/docs/` into a
#            hierarchical structure.
#
# 5.  **Cleanup**. Intermediate artifact directories and files created in `_build/`
#     (e.g., `agda-lagda_temp/`, `agda-docs`, `macros.json`) are removed.
#
#
# USAGE
#
# From the main project directory (e.g., `formal-ledger-specifications/`):
#   python build-tools/scripts/tex2md/build.py [--run-agda]
#   (or, using Python's module execution: python -m scripts.mkdocs.build [--run-agda])
#
#
# KEY OUTPUTS
#
# -  _build/agda_snapshot_src/: the new Agda source code (`.lagda.md`) files,
#    with the same directory structure as under the original `src/` directory.
#    This serves as the primary input to the agda command for type checking, or
#    the `agda --html` command for html code-highlighting for web page generation.
#
# -  _build/website/mkdocs/src/: complete source for mkdocs site.
#    In this directory, you can run the commands `mkdocs build` or `mkdocs serve`.
#    This directory contains
#
#    -  `./docs/`: final `.md` documentation pages (using flat, dot-separated names
#       like `Ledger.Transaction.md`), CSS, JS.
#
#    -  `./mkdocs.yml`: configuration file with mkdocs site structure and navigation.
#
# -  _build/website/mdbook/: complete source for mdbook site.
#    In this directory, you can run the commands `mdbook build` or `mdbook serve`.
#    This directory contains
#
#    -  `./src/`: final `.md` documentation pages (using flat,
#       dot-separated names like `Ledger.Transaction.md`), CSS, JS.
#       (output of `agda --html` command goes here)
#
#    -  `./src/SUMMARY.md`: mdbook navigation structure.
#
#    -  `./book.toml`: mdbook configuration file.
#
# -  _build/build.log: detailed log file of the build script's execution.
#
#
# INTERMEDIATE ARTIFACTS
#
# - _build/website/macros.json        (output of generate_macros_json.py)
# - _build/website/lagda_temp/        (output of preprocess.py; input to pandoc+lua)
# - _build/website/code_blocks_json/  (output of preprocess.py; input to postprocess.py)
# - _build/website/md_intermediate/   (output of pandoc+lua; input to postprocess.py)
# - _build/agda-docs/         (output of `agda --html` if --run-agda flag used,
#                             otherwise output of postprocess.py )
import os
import sys
import subprocess
import json
import re
import shutil
from pathlib import Path
from typing import List, Dict, Optional, Any, TypedDict
import logging
import argparse

try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False
try:
    from agda2lagda import convert_agda_to_lagda_md
except ImportError:
    print(f"FATAL: Could not import 'convert_agda_to_lagda_md'. Ensure 'agda2lagda.py' is in {SCRIPTS_DIR}.", file=sys.stderr)
    sys.exit(1)

# --- Custom Type Definitions ---
class ProcessedFileInfo(TypedDict):
    original_path: Path
    temp_path: Path
    code_blocks_json_path: Path
    intermediate_md_path: Path
    snapshot_target_path: Path
    final_flat_md_filename: str
    relative_path_original: Path

class LabelTargetInfo(TypedDict):
    file: str
    anchor: str
    caption_text: str


# === CONFIGURATION ===
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent.parent # assume build.py is in ./build-tools/scripts/tex2md
#
# --- INPUTS --------------------------------------
SRC_DIR = PROJECT_ROOT / "src"                         # original .lagda source
LIB_EXTS_DIR = PROJECT_ROOT / "src-lib-exts"           # original .agda lib source
BUILD_TOOLS = PROJECT_ROOT / "build-tools"             # build tools directory
# - script paths -
SCRIPTS_DIR = BUILD_TOOLS / "scripts"                  # scripts and helpers
TEX2MD_DIR = SCRIPTS_DIR / "tex2md"                    # this script and helpers
GENERATE_MACROS_PY = TEX2MD_DIR / "generate_macros_json.py"
PREPROCESS_PY = TEX2MD_DIR / "preprocess.py"
POSTPROCESS_PY = TEX2MD_DIR / "postprocess.py"
LUA_FILTER = TEX2MD_DIR / "agda-filter.lua"
# - static content -
STATIC_DIR = BUILD_TOOLS / "static"                    # static files for mkdocs, mdbook, etc
LATEX_DIR = STATIC_DIR / "latex"                       # LaTeX path
MACROS_STY_PATH = LATEX_DIR / "macros.sty"             # LaTeX macros
WEBSITE_STATIC_DIR = STATIC_DIR / "website"            # static website files
MKDOCS_STATIC_DIR = WEBSITE_STATIC_DIR / "mkdocs"
MKDOCS_STATIC_NAV_YML = MKDOCS_STATIC_DIR / "nav.yml"  # mkdocs navigation template
MKDOCS_STATIC_SRC_DIR = MKDOCS_STATIC_DIR / "src"
MKDOCS_STATIC_DOCS_DIR = MKDOCS_STATIC_SRC_DIR / "docs"
MKDOCS_STATIC_CSS_DIR = MKDOCS_STATIC_DOCS_DIR / "css"
MKDOCS_STATIC_JS_DIR = MKDOCS_STATIC_DOCS_DIR / "js"
MKDOCS_STATIC_CUSTOM_CSS_SOURCE = MKDOCS_STATIC_CSS_DIR / "custom.css"
MKDOCS_STATIC_CUSTOM_JS_SOURCE = MKDOCS_STATIC_JS_DIR / "js" / "custom.js"
MKDOCS_STATIC_INDEX = MKDOCS_STATIC_SRC_DIR / "docs" / "index.md"
MDBOOK_STATIC_DIR = WEBSITE_STATIC_DIR / "mdbook"
MDBOOK_BOOK_TOML_TEMPLATE = MDBOOK_STATIC_DIR / "book.toml"
MDBOOK_STATIC_DOCS_DIR = MDBOOK_STATIC_DIR / "src"
MDBOOK_SUMMARY_MD_TEMPLATE = MDBOOK_STATIC_DOCS_DIR / "SUMMARY.md"
MDBOOK_STATIC_CSS_DIR = MDBOOK_STATIC_DOCS_DIR / "css"
MDBOOK_STATIC_JS_DIR = MDBOOK_STATIC_DOCS_DIR / "js"
MDBOOK_STATIC_CUSTOM_CSS_SOURCE = MDBOOK_STATIC_CSS_DIR / "custom.css"
MDBOOK_STATIC_CUSTOM_JS_SOURCE = MDBOOK_STATIC_JS_DIR / "js" / "custom.js"
MDBOOK_STATIC_INDEX = MDBOOK_STATIC_DOCS_DIR / "index.md"
#
# --- OUTPUTS -------------------------------------------
BUILD_DIR = PROJECT_ROOT / "_build"                     # top-level build dir
#
AGDA_SNAPSHOT_SRC_DIR = BUILD_DIR / "agda_snapshot_src" # markdown-based literate Agda source code:
                                                        #   output of postprocess.py
                                                        #   input to `agda --html`
                                                        #   input to shake (if `agda --html` relegated to shake)
# Initially, the AGDA_SNAPSHOT_SRC_DIR contains whatever was in src/:
# - some modules as pre-existing .lagda.md files
# - some modules as .agda files
# - some modules as .lagda (LaTeX) files
# Crucially, for any given module, only ONE of these types will exist.
#
AGDA_SNAPSHOT_LIB_EXTS_DIR = BUILD_DIR / "agda_snapshot_lib_exts" # copy of Agda library extensions
# - migration pipeline products -
BUILD_WEBSITE_DIR = BUILD_DIR / "website"                   # website build directory
MACROS_JSON = BUILD_WEBSITE_DIR / "macros.json"             # output of generate_macros_json.py; input to preprocess.py
TEMP_DIR = BUILD_WEBSITE_DIR / "lagda_temp"                 # intermediate latex:  output of preprocess.py; input to pandoc+lua
CODE_BLOCKS_DIR = BUILD_WEBSITE_DIR / "code_blocks_json"    # output of preprocess.py; input to postprocess.py
INTERMEDIATE_MD_DIR = BUILD_WEBSITE_DIR / "md_intermediate" # intermediate `.lagda.md`: output of pandoc+lua; intput to postprocess.py
AGDA_DOCS_STAGING_DIR = BUILD_WEBSITE_DIR / "agda-docs"     # output of `agda --html` command if --run-agda flag used,
#                                                           # otherwise output of postprocess.py
# - generated directories for mkdocs site -
MKDOCS_BUILD_DIR = BUILD_WEBSITE_DIR / "mkdocs"
MKDOCS_SRC_DIR = MKDOCS_BUILD_DIR / "src"
MKDOCS_DOCS_DIR = MKDOCS_SRC_DIR / "docs"
MKDOCS_CSS_DIR = MKDOCS_DOCS_DIR / "css"
MKDOCS_JS_DIR = MKDOCS_DOCS_DIR / "js"
# - generated directories for mdbook site -
MDBOOK_BUILD_DIR = BUILD_DIR / "mdbook"
MDBOOK_SRC_DIR = MDBOOK_BUILD_DIR
MDBOOK_DOCS_DIR = MDBOOK_SRC_DIR / "src"
MDBOOK_CSS_DIR = MDBOOK_DOCS_DIR / "css"
MDBOOK_JS_DIR = MDBOOK_DOCS_DIR / "js"
# - logging -
LOG_FILE = BUILD_DIR / "build.log"


# Helper class for managing paths within .lagda processing loop.
class LagdaProcessingPaths:
    """
    Manage set of file paths for processing a single .lagda file.
    All paths constructed based on `relative_path` from source directory.
    """
    def __init__(self, relative_path: Path):
        self.relative = relative_path # e.g., Path("Module/File.lagda")

        # intermediate file paths based on global directories
        self.temp_lagda = TEMP_DIR / self.relative.with_suffix(".lagda.temp")
        self.code_blocks_json = CODE_BLOCKS_DIR / self.relative.with_suffix(".codeblocks.json")
        self.intermediate_md = INTERMEDIATE_MD_DIR / self.relative.with_suffix(".md.intermediate")

        # snapshot related paths
        self.snapshot_original_lagda = AGDA_SNAPSHOT_SRC_DIR / self.relative # Original .lagda in snapshot
        # target for processed .lagda.md in the snapshot
        self.snapshot_target_lagda_md = AGDA_SNAPSHOT_SRC_DIR / self.relative.with_suffix(".lagda.md")

        # path for .md file in mkdocs docs directory (before Agda html processing)
        self.mkdocs_interim_md = MKDOCS_DOCS_DIR / self.relative.with_suffix(".md")

        # path for .md file in mdbook src directory (before Agda html processing)
        self.mdbook_interim_md = MDBOOK_DOCS_DIR / self.relative.with_suffix(".md")

    def ensure_parent_dirs_exist(self) -> None:
        """Create all needed parent directories for output files of this specific relative_path."""
        # Collect all unique parent directories that need to exist for this file's outputs
        # Note: base directories (TEMP_DIR, etc.) are created by setup_directories(); this is for
        #       subdirectories *within* those base output directories.
        parents_to_create = {
            self.temp_lagda.parent,
            self.code_blocks_json.parent,
            self.intermediate_md.parent,
            self.snapshot_target_lagda_md.parent, # parent of target in snapshot
            self.mkdocs_interim_md.parent,
            self.mdbook_interim_md.parent,
        }
        for parent_dir in parents_to_create:
            parent_dir.mkdir(parents=True, exist_ok=True)

# Logging Setup
def setup_logging() -> None:
    """Configures logging to file (DEBUG) and console (INFO) without basicConfig."""
    log_formatter = logging.Formatter('%(asctime)s - %(levelname)-8s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

    # get root logger
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG) # set lowest level for logger itself

    # clear existing handlers (important if this function could be called multiple times)
    if logger.hasHandlers():
        logger.handlers.clear()

    # file handler (DEBUG level)
    try:
        # ensure directory for LOG_FILE exists just before opening
        LOG_FILE.parent.mkdir(parents=True, exist_ok=True) # for extra safety
        file_handler = logging.FileHandler(LOG_FILE, mode='w', encoding='utf-8')
        file_handler.setFormatter(log_formatter)
        file_handler.setLevel(logging.DEBUG)
        logger.addHandler(file_handler)
    except Exception as e:
        # If this fails, we need to know why. Print to stderr.
        print(f"CRITICAL LOGGING ERROR: Failed to set up file logging to {LOG_FILE}: {e}", file=sys.stderr)
        # Optionally, re-raise or exit if file logging is critical
        # For now, let it continue so console logging might still work.

    # Console handler (INFO level)
    console_handler = logging.StreamHandler(sys.stderr)
    console_handler.setFormatter(log_formatter)
    console_handler.setLevel(logging.INFO)  # set this to DEBUG for troubleshooting
    logger.addHandler(console_handler)

    # This message might not make it to file if file_handler failed,
    # but will go to console if console_handler working.
    logging.info("Logging setup complete. Log file: %s", LOG_FILE)

def setup_directories() -> None:
    """
    Cleans the main mkdocs and mdbook build artifacts directories and recreates
    essential subdirectories for the current build run.
    """

    ### Directories for intermediate build products and final staging.
    TEMP_DIR.mkdir(parents=True, exist_ok=True)              # for .lagda.temp files
    CODE_BLOCKS_DIR.mkdir(parents=True, exist_ok=True)       # for code_blocks.json
    INTERMEDIATE_MD_DIR.mkdir(parents=True, exist_ok=True)   # for .md.intermediate files
    AGDA_SNAPSHOT_SRC_DIR.mkdir(parents=True, exist_ok=True) # for Agda source snapshot
    AGDA_SNAPSHOT_LIB_EXTS_DIR.mkdir(parents=True, exist_ok=True) # for Agda source snapshot
    AGDA_DOCS_STAGING_DIR.mkdir(parents=True, exist_ok=True)

    ### MKDOCS ###
    # Only remove and recreate the specific mkdocs build directory.
    # Avoid deleting unrelated artifacts in _build/ (e.g., from shake/CI)!
    if MKDOCS_BUILD_DIR.exists(): # MKDOCS_BUILD_DIR is _build/mkdocs/
        logging.info(f"Cleaning up existing MkDocs build directory: {MKDOCS_BUILD_DIR}")
        shutil.rmtree(MKDOCS_BUILD_DIR)
    else:
        logging.info(f"MkDocs build directory does not exist, will create: {MKDOCS_BUILD_DIR}")

    logging.info(f"Creating fresh MkDocs build directories under: {MKDOCS_BUILD_DIR}")

    # Create final mkdocs site source structure (where content is copied to).
    MKDOCS_SRC_DIR.mkdir(parents=True, exist_ok=True)        # root for mkdocs.yml and docs/
    MKDOCS_DOCS_DIR.mkdir(parents=True, exist_ok=True)       # for final .md pages and assets
    MKDOCS_CSS_DIR.mkdir(parents=True, exist_ok=True)        # for CSS assets
    MKDOCS_JS_DIR.mkdir(parents=True, exist_ok=True)         # for JS assets

    ### MDBOOK ###
    # Only remove and recreate the specific mdbook build directory.
    # Avoid deleting unrelated artifacts in _build/ (e.g., from shake/CI)!
    if MDBOOK_BUILD_DIR.exists(): # MDBOOK_BUILD_DIR is _build/mdbook/
        logging.info(f"Cleaning up existing Mdbook build directory: {MDBOOK_BUILD_DIR}")
        shutil.rmtree(MDBOOK_BUILD_DIR)
    else:
        logging.info(f"Mdbook build directory does not exist, will create: {MDBOOK_BUILD_DIR}")

    logging.info(f"Creating fresh Mdbook build directories under: {MDBOOK_BUILD_DIR}")

    # Create final mdbook site source structure (where content is copied to).
    MDBOOK_SRC_DIR.mkdir(parents=True, exist_ok=True)        # root for book.toml and src/
    MDBOOK_DOCS_DIR.mkdir(parents=True, exist_ok=True)       # for final .md pages and assets
    MDBOOK_CSS_DIR.mkdir(parents=True, exist_ok=True)        # for CSS assets
    MDBOOK_JS_DIR.mkdir(parents=True, exist_ok=True)         # for JS assets



def cleanup_intermediate_artifacts() -> None:
    """
    Remove intermediate artifact directories and files generated within
    _build/ during the build process, keeping only the final outputs
    (like _build/agda_snapshot_src/ and _build/mkdocs/ and _build/mdbook/).
    """
    logging.info("Cleaning up intermediate build artifacts in _build/...")

    # directories to remove
    intermediate_dirs = [
        TEMP_DIR,
        CODE_BLOCKS_DIR,
        INTERMEDIATE_MD_DIR,
        AGDA_DOCS_STAGING_DIR
    ]

    # files to remove
    intermediate_files = [
        MACROS_JSON # generated from .sty
    ]

    for artifact_dir in intermediate_dirs:
        if artifact_dir.exists():
            try:
                shutil.rmtree(artifact_dir)
                logging.info(f"  Successfully removed intermediate directory: {artifact_dir.relative_to(BUILD_DIR)}")
            except OSError as e: # catch more specific error for rmtree
                logging.warning(f"  Warning: Could not remove intermediate directory {artifact_dir}: {e}")
        else:
            logging.debug(f"  Intermediate directory not found (already clean or not created): {artifact_dir.relative_to(BUILD_DIR)}")

    for artifact_file in intermediate_files:
        if artifact_file.exists():
            try:
                artifact_file.unlink()
                logging.info(f"  Successfully removed intermediate file: {artifact_file.relative_to(BUILD_DIR)}")
            except OSError as e: # catch more specific error for unlink
                logging.warning(f"  Warning: Could not remove intermediate file {artifact_file}: {e}")
        else:
            logging.debug(f"  Intermediate file not found (already clean or not created): {artifact_file.relative_to(BUILD_DIR)}")

    logging.info("Intermediate artifact cleanup complete.")


# --- Helper to run commands ---
def run_command(command_args: List[str],
                cwd: Optional[Path] = None,
                capture_output: bool = False,
                text: bool = False,
                check: bool = False,
                stdout_file: Optional[Path] = None) -> subprocess.CompletedProcess:
    """Runs a shell command, logs output/errors, optionally redirects stdout."""
    command_args_str = [str(arg) for arg in command_args]
    logging.info(f"Running: {' '.join(command_args_str)}")

    stdout_target = None
    stdout_content = None
    stderr_content = None

    if stdout_file:
        # Ensure parent directory exists for stdout_file
        Path(stdout_file).parent.mkdir(parents=True, exist_ok=True)
        stdout_target = open(stdout_file, "w", encoding="utf-8")
    elif capture_output:
        stdout_target = subprocess.PIPE

    try:
        process = subprocess.run(command_args_str, cwd=cwd,
                                 stdout=stdout_target,
                                 stderr=subprocess.PIPE, # Always capture stderr
                                 text=text, check=False, # Check manually after logging stderr
                                 encoding='utf-8')
        if stdout_file:
            stdout_target.close() # Ensure file is written and closed

        # Capture outputs if needed
        stdout_content = process.stdout
        stderr_content = process.stderr

        # Log stderr output as debug info, even on success
        if stderr_content:
             logging.debug(f"Stderr output for {' '.join(command_args_str)}:\n{stderr_content}")

        # Check return code if requested
        if check and process.returncode != 0:
            logging.error(f"Command failed with exit code {process.returncode}: {' '.join(command_args_str)}")
            # Log captured stdout only if it wasn't redirected and was captured
            if stdout_content and not stdout_file and capture_output: logging.error(f"Stdout:\n{stdout_content}")
            # Log captured stderr again for error context
            if stderr_content: logging.error(f"Stderr:\n{stderr_content}")
            raise subprocess.CalledProcessError(process.returncode, command_args_str,
                                                output=stdout_content, stderr=stderr_content)
        return process # Return completed process object

    except Exception as e:
        logging.error(f"Failed to run command {' '.join(command_args_str)}: {e}")
        raise # Re-raise exception after logging


# --- Helper for changing header phrases to link labels (slugs) ---
def slugify(text_to_slug: Optional[str]) -> str:
    """
    Generates a slug from text, similar to Python-Markdown's default.
    """
    if not text_to_slug: # handle empty string case
        return "section" # default slug for empty text
    text_to_slug = str(text_to_slug) # ensure text is string
    slug = text_to_slug.lower()

    # Remove unwanted characters
    slug = re.sub(r'[^\w\s-]', '', slug) # remove anything not a letter, number, underscore, or hyphen
    slug = re.sub(r'[-\s]+', '-', slug)  # replace whitespace and hyphen sequences with single hyphen
    slug = slug.strip('-')               # remove leading/trailing hyphens
    if not slug:         # if all chars stripped
        return "section" # default slug if original text yields empty slug
    return slug


def build_nav_from_flat_files(flat_file_paths_str_list) -> List[Dict[str, Any]]:
    """
    Builds a mkdocs navigation structure from a list of flat file path strings
    (e.g., ["Ledger.Transaction.md", "Ledger.Prelude.md", "index.md"]).
    Filenames are expected to be relative to mkdocs docs directory.
    """
    nav_tree = {}

    # Normalize and sort paths: "index.md" first, then lexicographically.
    # Ensures "Home" is first and the rest of the nav is stable.
    home_filename = "index.md"

    # Ensure all paths are just filenames for parsing
    processed_filenames = []
    for p_str in flat_file_paths_str_list:
        p_obj = Path(p_str)
        # If p_str was already like "docs/file.md", take name. If just "file.md", also take name.
        processed_filenames.append(p_obj.name)

    unique_filenames = sorted(
        list(set(processed_filenames)),
        key=lambda f: (f.lower() != home_filename.lower(), f) # home first, then case-insensitive sort
    )

    actual_home_file_for_nav = None

    for filename_str in unique_filenames: # e.g., "Ledger.Transaction.md"
        if filename_str.lower() == home_filename.lower():
            actual_home_file_for_nav = filename_str # store actual case used for "index.md"
            continue

        file_stem_flat = Path(filename_str).stem # "Ledger.Transaction" (removes ".md")

        # Split into parts: ["Ledger", "Transaction"]
        name_parts = file_stem_flat.split('.')

        # The last part is the page title, preceding parts form the section path.
        page_title_str = name_parts[-1] # .replace('_', ' ').replace('-', ' ').capitalize()
                                        # ^^^^^^^^ don't do this! (use raw module names)
        section_path_parts = name_parts[:-1] # e.g., ["Ledger"] or ["External", "Lib"]

        current_level_dict = nav_tree

        for section_name_raw in section_path_parts:
            section_title_str = section_name_raw #.replace('_', ' ').replace('-', ' ').capitalize()
                                                 # ^^^^^^^^ don't do this! (use raw module names)
            if section_title_str not in current_level_dict:
                current_level_dict[section_title_str] = {}
            elif not isinstance(current_level_dict[section_title_str], dict):
                # Conflict: A file was previously assigned here. Promote to section.
                # This case should be rare if naming conventions are consistent.
                logging.warning(
                    f"Navigation: Promoting '{section_title_str}' (which was a file link: "
                    f"'{current_level_dict[section_title_str]}') to a section to accommodate "
                    f"nested file '{filename_str}'."
                )
                # Create a placeholder for the original file, e.g., as an "Overview" page
                original_file_link = current_level_dict[section_title_str]
                current_level_dict[section_title_str] = {"Overview": original_file_link}

            current_level_dict = current_level_dict[section_title_str]

        # Add the current file (page) to its correct place in the navigation tree
        if page_title_str in current_level_dict:
            logging.warning(
                f"Navigation: Title '{page_title_str}' for file '{filename_str}' conflicts "
                f"with an existing item at the same level: '{current_level_dict[page_title_str]}'. "
                f"File '{filename_str}' will overwrite the previous entry if it was also a file, "
                f"or be skipped if it was a section."
            )
            # Only overwrite if the existing entry isn't a section (dict) itself
            if not isinstance(current_level_dict[page_title_str], dict):
                 current_level_dict[page_title_str] = filename_str
            else:
                # Attempt to add with a modified name if it's a section conflict
                current_level_dict[f"{page_title_str}/"] = current_level_dict[page_title_str]
                current_level_dict[page_title_str] = filename_str
        else:
            current_level_dict[page_title_str] = filename_str

    # Convert the dictionary tree to mkdocs nav list format (recursive helper)
    def format_nav_subtree(subtree_dict):
        nav_list_segment = []
        # Sort items by key (title) for consistent navigation order
        for title, content_or_path in sorted(subtree_dict.items(), key=lambda item: item[0]):
            if isinstance(content_or_path, dict): # it's a subsection dictionary
                nav_list_segment.append({title: format_nav_subtree(content_or_path)})
            else: # it's a file path string
                nav_list_segment.append({title: content_or_path})
        return nav_list_segment

    final_nav_structure = []
    if actual_home_file_for_nav:
        final_nav_structure.append({"Home": actual_home_file_for_nav})

    final_nav_structure.extend(format_nav_subtree(nav_tree))

    return final_nav_structure


# Helper function to determine flat name and copy/rename from snapshot
def copy_snapshot_file_with_flat_name(
    lagda_md_file_in_snapshot: Path,
    snapshot_root_dir: Path,
    target_docs_dir: Path   # <<< MKDOCS_DOCS_DIR or MDBOOK_DOCS_DIR
) -> str | None:
    """
    Calculates the flat MD filename for a snapshot file, copies the snapshot
    file to the target docs directory with that flat name.
    Returns the flat filename string (e.g., "Module.File.md") if successful, else None.
    """
    try:
        relative_path_from_snapshot_root = lagda_md_file_in_snapshot.relative_to(snapshot_root_dir)

        module_name_parts = list(relative_path_from_snapshot_root.parent.parts)
        file_stem = relative_path_from_snapshot_root.name
        if file_stem.endswith(".lagda.md"): file_stem = file_stem[:-len(".lagda.md")]
        elif file_stem.endswith(".lagda"): file_stem = file_stem[:-len(".lagda")]
        elif file_stem.endswith(".md"): file_stem = file_stem[:-len(".md")]

        is_index_file = file_stem.lower() == "index"
        if not module_name_parts and is_index_file: module_name_flat = "index"
        elif not module_name_parts: module_name_flat = file_stem
        else:
            if not is_index_file: module_name_parts.append(file_stem)
            module_name_flat = ".".join(part for part in module_name_parts if part)

        final_flat_filename = module_name_flat + ".md"
        target_full_path = target_docs_dir / final_flat_filename

        # check for overwrite
        if target_full_path.exists():
            logging.warning(f"  Overwrite: Generated file '{target_full_path.name}' "
                            f"is overwriting an existing file (likely from static template) "
                            f"at '{target_full_path.relative_to(PROJECT_ROOT)}'.")

        target_full_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(lagda_md_file_in_snapshot, target_full_path)
        logging.debug(f"  Copied snapshot file {lagda_md_file_in_snapshot.name} to {target_full_path.name} (flat name)")
        return final_flat_filename
    except Exception as e:
        logging.error(f"  Failed to copy/rename snapshot file {lagda_md_file_in_snapshot.name} to flat name: {e}", exc_info=True)
        return None


def macros_path(
    macros_json_target_path: Path,
    generator_script: Path,
    macros_sty_source: Path
) -> Path:
    """Ensures macros.json exists, generating it if necessary."""
    logging.info(f"Checking for {macros_json_target_path.name}...")
    if generator_script.exists() and macros_sty_source.exists():
        if not macros_json_target_path.exists() or macros_sty_source.stat().st_mtime > macros_json_target_path.stat().st_mtime:
            logging.info(f"Generating {macros_json_target_path.name} from {macros_sty_source.name}...")
            run_command(["python", str(generator_script), str(macros_sty_source), str(macros_json_target_path)])
        else:
            logging.info(f"Using existing and up-to-date {macros_json_target_path.name}.")
    elif not macros_json_target_path.exists():
        logging.error(f"{macros_json_target_path.name} not found and cannot be generated. Exiting.")
        sys.exit(1)
    else:
        logging.info(f"Using existing {macros_json_target_path.name} (generator or source .sty not found).")
    return macros_json_target_path


def create_agda_snapshots(
    original_src_dir: Path,
    snapshot_src_target_dir: Path,
    original_lib_exts_dir: Path,
    snapshot_lib_exts_target_dir: Path
) -> None:
    """Copies Agda source and src-lib-exts to their snapshot directories."""
    logging.info(f"Creating Agda source snapshot in {snapshot_src_target_dir.relative_to(PROJECT_ROOT)}...")
    shutil.copytree(original_src_dir, snapshot_src_target_dir, dirs_exist_ok=True)

    logging.info(f"Creating Agda src-lib-exts snapshot in {snapshot_lib_exts_target_dir.relative_to(PROJECT_ROOT)}...")
    shutil.copytree(original_lib_exts_dir, snapshot_lib_exts_target_dir, dirs_exist_ok=True)


def convert_agda_to_lagda(snapshot_src_dir: Path, project_root_for_logging: Path) -> None:
    """Converts .agda files to .lagda.md within the snapshot directory."""
    logging.info("Converting .agda files to .lagda.md in the src snapshot directory...")
    if 'convert_agda_to_lagda_md' not in globals():
        logging.error("agda2lagda.convert_agda_to_lagda_md not available. Skipping .agda conversion.")
        return # Or raise an error if critical
    try:
        conversion_success = convert_agda_to_lagda_md(
            str(snapshot_src_dir),
            project_root_for_logging=project_root_for_logging
        )
        if not conversion_success:
            logging.error("Failure during .agda to .lagda.md conversion. Exiting.")
            sys.exit(1) # Or raise an exception
    except Exception as e:
        logging.error(f"Error during .agda to .lagda.md conversion: {e}", exc_info=True)
        sys.exit(1) # Or raise


def generate_agda_lib_file(
    snapshot_src_dir: Path,
    snapshot_lib_exts_dir: Path,
    agda_lib_dependencies: List[str]
) -> Path:
    """Generate .agda-lib file in snapshot directory."""
    agda_lib_includes = [".", str(snapshot_lib_exts_dir.resolve())] # Use resolved absolute path for robustness
    agda_lib_content = f"name: {snapshot_src_dir.name}-build\n" \
                       f"depend: {' '.join(agda_lib_dependencies)}\n" \
                       f"include: {' '.join(agda_lib_includes)}"
    snapshot_lib_file = snapshot_src_dir / f"{snapshot_src_dir.name}.agda-lib"
    try:
        with open(snapshot_lib_file, "w", encoding="utf-8") as f:
            f.write(agda_lib_content)
        logging.info(f"Generated {snapshot_lib_file.name} in snapshot directory: {snapshot_lib_file}")
    except Exception as e:
        logging.error(f"Failed to write {snapshot_lib_file.name}: {e}", exc_info=True)
        sys.exit(1) # Or raise
    return snapshot_lib_file

def run_latex_preprocessing_stage(
    original_latex_lagda_files: List[Path],
    src_dir_root: Path,       # to calculate relative_path
    macros_json_path: Path,
    temp_dir: Path,           # base for temp_lagda
    code_blocks_dir: Path     # base for code_blocks_json
) -> List[ProcessedFileInfo]:
    """Runs preprocess.py on original LaTeX .lagda files."""
    processed_files_info: List[ProcessedFileInfo] = []
    if not original_latex_lagda_files:
        logging.info("No original LaTeX .lagda files found to preprocess.")
        return processed_files_info

    logging.info("\n--- Running preprocess.py for all original LaTeX .lagda files ---")
    for lagda_file_abs_path in original_latex_lagda_files:
        relative_path = lagda_file_abs_path.relative_to(src_dir_root)
        logging.info(f"Preprocessing: {relative_path}")

        paths = LagdaProcessingPaths(relative_path) # Uses global TEMP_DIR, CODE_BLOCKS_DIR etc.
                                                    # Pass temp_dir, code_blocks_dir if these should not be global
        paths.ensure_parent_dirs_exist()

        try:
            run_command([
                "python", str(PREPROCESS_PY), # PREPROCESS_PY would be a global constant
                str(lagda_file_abs_path),
                str(macros_json_path),
                str(paths.code_blocks_json)
            ], stdout_file=str(paths.temp_lagda))

            # Determine the final flat MD filename
            module_name_parts = list(relative_path.parent.parts)
            file_stem = relative_path.stem # .stem removes the final suffix, e.g. .lagda
            # (adjust if .lagda.tex or similar complex extensions exist)

            is_index_file_stem = file_stem.lower() == "index"
            if not module_name_parts and is_index_file_stem: flat_module_name_base = "index"
            elif not module_name_parts: flat_module_name_base = file_stem
            else:
                name_parts_for_join = list(module_name_parts)
                if not is_index_file_stem: name_parts_for_join.append(file_stem)
                flat_module_name_base = ".".join(part for part in name_parts_for_join if part)
            final_flat_md_filename = flat_module_name_base + ".md"

            processed_files_info.append({
                "original_path": lagda_file_abs_path,
                "temp_path": paths.temp_lagda,
                "code_blocks_json_path": paths.code_blocks_json,
                "intermediate_md_path": paths.intermediate_md,
                "snapshot_target_path": paths.snapshot_target_lagda_md,
                "final_flat_md_filename": final_flat_md_filename,
                "relative_path_original": relative_path
            })
        except Exception as e:
            logging.error(f"Error during preprocess.py for {relative_path}: {e}", exc_info=True)
            # Consider whether to continue or re-raise/sys.exit
    return processed_files_info


def build_global_label_map(
    processed_files_info: List[ProcessedFileInfo], # Uses 'temp_path' and 'final_flat_md_filename'
    build_mkdocs_dir: Path # To store labels_map.json
) -> Optional[Path]:
    """Builds and saves the global label-to-target map from .lagda.temp files."""
    global_labels_to_targets: Dict[str, LabelTargetInfo] = {}
    if not processed_files_info:
        logging.info("No processed files to build label map from. Skipping map generation.")
        return None
    logging.info("\n--- Building global label map from processed .lagda.temp files ---")
    for file_info in processed_files_info:
        temp_file_path = file_info["temp_path"]
        final_flat_filename_for_map = file_info["final_flat_md_filename"]
        if temp_file_path.exists():
            with open(temp_file_path, 'r', encoding='utf-8') as f_temp:
                temp_content = f_temp.read()
            # Find all @@FIGURE_BLOCK_TO_SUBSECTION@@label=L@@caption=C@@ placeholders
            for match in re.finditer(r"@@FIGURE_BLOCK_TO_SUBSECTION@@label=(.*?)@@caption=(.*?)@@", temp_content, flags=re.DOTALL):
                # Unescape "@@" if it was escaped in preprocess.py
                original_label_id = match.group(1).replace("@ @", "@@")
                caption_text = match.group(2).replace("@ @", "@@")
                target_anchor_slug = slugify(caption_text)
                if original_label_id in global_labels_to_targets:
                    # Log warning for redefinition (as in original code)
                    pass # Simplified for brevity
                global_labels_to_targets[original_label_id] = {
                    "file": final_flat_filename_for_map,
                    "anchor": f"#{target_anchor_slug}",  # anchor includes '#'
                    "caption_text": caption_text         # store original caption for link text
                }
        else:
            logging.warning(f"Expected .lagda.temp file not found for label mapping: {temp_file_path}")
    labels_map_json_path = build_mkdocs_dir / "labels_map.json"
    try:
        with open(labels_map_json_path, 'w', encoding='utf-8') as f_map:
            json.dump(global_labels_to_targets, f_map, indent=2)
        logging.info(f"Global label-to-target map saved to {labels_map_json_path}")
        return labels_map_json_path
    except Exception as e:
        logging.error(f"Failed to save labels_map.json: {e}", exc_info=True)
        return None # Indicate failure


def run_latex_conversion_stage(
    processed_files_info: List[ProcessedFileInfo],
    labels_map_json_path: Optional[Path], # Path to labels_map.json or dummy
    lua_filter_path: Path,
    postprocess_script_path: Path,
    build_mkdocs_dir: Path, # For dummy_labels_map.json
    agda_snapshot_src_dir: Path, # For removing original .lagda
) -> List[Path]:
    """Runs Pandoc and postprocess.py for LaTeX files, updating the snapshot.
    Returns a list of .lagda.md files successfully generated in the snapshot.
    """
    generated_snapshot_files: List[Path] = []
    if not processed_files_info:
        return generated_snapshot_files
    logging.info("\n--- Running Pandoc & postprocess.py for original LaTeX .lagda files ---")

    # Prepare dummy map path if needed
    dummy_map_path = build_mkdocs_dir / "dummy_labels_map.json"
    actual_labels_map_path_for_postprocess = labels_map_json_path
    if not (labels_map_json_path and labels_map_json_path.exists()):
        if not dummy_map_path.exists():
            with open(dummy_map_path, 'w', encoding='utf-8') as f_dummy: json.dump({}, f_dummy)
        actual_labels_map_path_for_postprocess = dummy_map_path
        logging.warning(f"Using dummy labels map: {dummy_map_path}")

    for file_info in processed_files_info:
        relative_path = file_info["relative_path_original"]
        logging.info(f"Pandoc/Postprocessing: {relative_path}")
        temp_lagda_path = file_info["temp_path"]
        intermediate_md_path = file_info["intermediate_md_path"]          # \
        current_code_blocks_json = file_info["code_blocks_json_path"]     #  from LagdaProcessingPaths
        snapshot_target_lagda_md_path = file_info["snapshot_target_path"] # /
        try:
            # -- pandoc+lua --
            run_command([
                "pandoc", str(temp_lagda_path),
                "-f", "latex", "-t", "gfm+attributes",
                "--lua-filter", str(lua_filter_path),
                "-o", str(intermediate_md_path)
            ])
            # -- postprocess --
            postprocess_args = [
                "python", str(postprocess_script_path),
                str(intermediate_md_path),
                str(current_code_blocks_json),
                str(actual_labels_map_path_for_postprocess),
                str(snapshot_target_lagda_md_path) # Output file
            ]
            run_command(postprocess_args)

            if snapshot_target_lagda_md_path.exists():
                generated_snapshot_files.append(snapshot_target_lagda_md_path)
                logging.info(f"  Successfully generated {snapshot_target_lagda_md_path.relative_to(agda_snapshot_src_dir)}")
                # Remove original .lagda from snapshot
                snapshot_original_latex_lagda = agda_snapshot_src_dir / relative_path
                if snapshot_original_latex_lagda.exists() and snapshot_original_latex_lagda.is_file():
                    snapshot_original_latex_lagda.unlink(missing_ok=True)
                    logging.info(f"  Removed original .lagda from snapshot: {snapshot_original_latex_lagda.name}")
            else:
                logging.error(f"  Postprocessed file not found: {snapshot_target_lagda_md_path.name}")

        except Exception as e:
            logging.error(f"Error during Pandoc/Postprocess for {relative_path}: {e}", exc_info=True)
            # Decide on error handling: continue, or re-raise?
    return generated_snapshot_files



def collect_all_literate_md_in_snapshot(snapshot_src_dir: Path) -> List[Path]:
    """Globs all .lagda.md files in the snapshot directory and sorts them."""
    all_lagda_md_files = sorted(list(snapshot_src_dir.rglob("*.lagda.md")))
    logging.info(f"\nFound {len(all_lagda_md_files)} total unique literate .md files in snapshot for Agda processing.")
    for f_path in all_lagda_md_files:
        logging.debug(f"  Candidate for Agda: {f_path.relative_to(snapshot_src_dir)}")
    return all_lagda_md_files

def populate_agda_docs_staging(
    run_agda_html_flag: bool,
    all_snapshot_lagda_md_files: List[Path], # from collect_all_literate_md_in_snapshot
    agda_snapshot_src_dir: Path,             # e.g., _build/agda_snapshot_src
    agda_docs_staging_dir: Path,             # e.g., _build/agda-docs
    master_agda_file_name: str = "Ledger.lagda.md" # default master Agda file for --html
) -> List[Path]: # Return list of Path objects for .md files in agda_docs_staging_dir
    """
    Populates the _build/agda-docs/ staging directory.
    If run_agda_html_flag is True, runs `agda --html`.
    Otherwise, copies files from snapshot, renaming them to flat "ModuleName.md" format.
    Returns a list of Path objects for the final .md files in agda_docs_staging_dir.
    """
    logging.info(
        f"\n--- Populating Agda docs staging directory: "
        f"{agda_docs_staging_dir.relative_to(PROJECT_ROOT)} ---" # assuming PROJECT_ROOT is global
    )
    agda_docs_staging_dir.mkdir(parents=True, exist_ok=True) # ensure it exists

    final_md_files_in_staging: List[Path] = []
    effective_run_agda_html = run_agda_html_flag

    # 1. Determine if Agda --html should effectively run
    if run_agda_html_flag:
        master_agda_file_in_snapshot = agda_snapshot_src_dir / master_agda_file_name
        if not master_agda_file_in_snapshot.exists():
            logging.error(
                f"Master Agda file '{master_agda_file_name}' not found in snapshot: "
                f"{master_agda_file_in_snapshot}"
            )
            logging.warning("Skipping Agda --html. Falling back to copying snapshot files.")
            effective_run_agda_html = False

    # 2. Attempt to run Agda --html if requested and master file exists
    if effective_run_agda_html:
        logging.info(f"Running Agda --html, outputting directly to {agda_docs_staging_dir}...")
        try:
            # Construct the path to master_agda_file_name relative to agda_snapshot_src_dir
            # if master_agda_file_name might include path components.
            # If it's always a direct child, master_agda_file_name is fine as is.
            # Your current script uses master_agda_file_name directly when cwd is agda_snapshot_src_dir.

            run_command( # Assuming your run_command helper is available
                [
                    "agda", "--html", "--html-highlight=auto", # or your preferred highlighting
                    f"--html-dir={agda_docs_staging_dir.resolve()}",
                    "-i", ".", # Include path for current directory (snapshot root)
                    # Add other include paths if your Agda project needs them from snapshot_lib_exts_dir
                    # e.g., "-i", str(AGDA_SNAPSHOT_LIB_EXTS_DIR.resolve()),
                    master_agda_file_name # Path relative to cwd (agda_snapshot_src_dir)
                ],
                cwd=agda_snapshot_src_dir.resolve()
            )
            logging.info(f"Agda --html command completed. Files generated in {agda_docs_staging_dir}.")

            # Collect generated .md files
            for gen_file in agda_docs_staging_dir.glob("*.md"):
                final_md_files_in_staging.append(gen_file)

            if not final_md_files_in_staging and all_snapshot_lagda_md_files:
                logging.warning(
                    f"Agda --html ran but no '.md' files were collected from {agda_docs_staging_dir}. "
                    "This might indicate an issue with Agda's output or the master file."
                )

        except Exception as e_agda: # Catch subprocess.CalledProcessError or general exceptions
            logging.error(f"Agda --html command failed: {e_agda}", exc_info=True)
            logging.warning("Falling back to copying snapshot files (no Agda HTML highlighting).")
            effective_run_agda_html = False # Force fallback

    # 3. Fallback: Copy .lagda.md files from snapshot if Agda --html was not run or failed
    if not effective_run_agda_html:
        logging.info(
            f"Copying .lagda.md files from {agda_snapshot_src_dir.relative_to(PROJECT_ROOT)} "
            f"to {agda_docs_staging_dir.relative_to(PROJECT_ROOT)} with flat names..."
        )
        if not all_snapshot_lagda_md_files:
            logging.warning(
                f"No processed literate .md files found in {agda_snapshot_src_dir} to copy to staging."
            )

        for lagda_md_file_in_snapshot in all_snapshot_lagda_md_files:
            # copy_snapshot_file_with_flat_name expects:
            # 1. Path to the .lagda.md file in the snapshot.
            # 2. The root of the snapshot directory (for calculating relative path for flat name).
            # 3. The target directory where the flat-named file will be placed.
            flat_filename_str = copy_snapshot_file_with_flat_name( # Your existing helper
                lagda_md_file_in_snapshot,
                agda_snapshot_src_dir,
                agda_docs_staging_dir
            )
            if flat_filename_str:
                final_md_files_in_staging.append(agda_docs_staging_dir / flat_filename_str)
            else:
                logging.warning(f"Failed to process/copy file: {lagda_md_file_in_snapshot}")

    num_staged_files = len(final_md_files_in_staging)
    logging.info(
        f"Populated {agda_docs_staging_dir.relative_to(PROJECT_ROOT)} with {num_staged_files} file(s)."
    )

    # Return a sorted, unique list of Path objects
    return sorted(list(set(final_md_files_in_staging)))


def copy_staging_to_site_docs(
    agda_docs_staging_dir: Path, # e.g., _build/agda-docs/
    target_site_docs_dir: Path,  # e.g., _build/mkdocs/src/docs/ or _build/mdbook/src/
    site_name: str               # "MkDocs" or "mdbook" for logging
) -> List[str]: # Returns a list of flat .md filenames (basenames) found at the top level of target
    """
    Copies the ENTIRE contents of agda_docs_staging_dir to target_site_docs_dir.
    Ensures the target directory is clean or that dirs_exist_ok handles overwrites.
    Returns a list of the basenames of .md files found at the top level of target_site_docs_dir.
    """
    logging.info(
        f"\n--- Populating {site_name} site docs from "
        f"{agda_docs_staging_dir.relative_to(PROJECT_ROOT)} "
        f"to {target_site_docs_dir.relative_to(PROJECT_ROOT)} ---"
    )

    if not agda_docs_staging_dir.exists() or not any(agda_docs_staging_dir.iterdir()):
        logging.warning(f"Staging directory {agda_docs_staging_dir} is empty or does not exist. "
                        f"No files to copy for {site_name}.")
        target_site_docs_dir.mkdir(parents=True, exist_ok=True) # Ensure target dir exists
        return []

    # Ensure the target_site_docs_dir exists and is empty or ready for overwrite
    if target_site_docs_dir.exists():
        logging.debug(f"Target directory {target_site_docs_dir} exists. Overwriting content.")
        # shutil.rmtree(target_site_docs_dir)
        # Option 1: Clean wipe. (Be careful if static files were copied here first.)
        # target_site_docs_dir.mkdir(parents=True, exist_ok=True)
    else:
        target_site_docs_dir.mkdir(parents=True, exist_ok=True)

    # Option 2 (Preferred if target_site_docs_dir might have other static content):
    # Copy contents, overwriting existing files.
    # For shutil.copytree, target must not exist or be empty if dirs_exist_ok=False (default)
    # With dirs_exist_ok=True (Python 3.8+), it works like `cp -rT SOURCEDIR TARGETDIR`
    try:
        shutil.copytree(agda_docs_staging_dir, target_site_docs_dir, dirs_exist_ok=True)
        logging.info(f"Successfully copied all contents from {agda_docs_staging_dir.name} "
                     f"to {target_site_docs_dir.name} for {site_name}.")
    except Exception as e:
        logging.error(
            f"  Failed to copy directory {agda_docs_staging_dir.name} "
            f"to {target_site_docs_dir.name} for {site_name}: {e}",
            exc_info=True
        )
        return [] # Return empty list on failure

    # Collect .md file names from the target directory for navigation purposes
    # We only collect from the top level of target_site_docs_dir as Agda flattens modules.
    copied_md_filenames: List[str] = []
    for item in target_site_docs_dir.iterdir():
        if item.is_file() and item.suffix == ".md":
            copied_md_filenames.append(item.name)

    logging.info(f"Found {len(copied_md_filenames)} .md files in {target_site_docs_dir.name} for {site_name} navigation.")
    return sorted(list(set(copied_md_filenames)))


def deploy_static_mkdocs_assets(
    mkdocs_docs_dir: Path,
    mkdocs_css_dir: Path,
    mkdocs_js_dir: Path,
    run_agda_html_flag: bool, # To know if Agda.css is needed
    current_nav_files: List[str], # To check if index.md is already there
    # Paths to static assets (could be part of a config dict/object)
    custom_css_source: Path,
    custom_js_source: Path,
    index_md_template_source: Path,
    project_root: Path # For relative logging
) -> List[str]:
    """Copies static assets like CSS, JS, and index.md template to the docs folder.
    Returns the updated list of nav files (potentially adding index.md).
    """
    logging.info("\nAssembling static assets for MkDocs site...")
    assets_to_copy: Dict[Path, Path] = {} # Source -> Destination

    # Agda.css
    if run_agda_html_flag:
        try:
            agda_css_proc = run_command(["agda", "--print-agda-data-dir"], capture_output=True, check=False, text=True)
            if agda_css_proc.returncode == 0 and agda_css_proc.stdout:
                agda_data_dir = Path(agda_css_proc.stdout.strip())
                agda_css_source = agda_data_dir / "html" / "Agda.css"
                if agda_css_source.exists():
                    assets_to_copy[agda_css_source] = mkdocs_css_dir / "Agda.css"
                else: logging.warning(f"Agda.css not found at: {agda_css_source}")
            else: logging.warning(f"Could not find Agda.css via 'agda --print-agda-data-dir'. Stderr: {agda_css_proc.stderr}")
        except Exception as e: logging.warning(f"Error trying to find Agda.css: {e}")

    # Custom CSS/JS
    if custom_css_source.exists(): assets_to_copy[custom_css_source] = mkdocs_css_dir / custom_css_source.name
    if custom_js_source.exists(): assets_to_copy[custom_js_source] = mkdocs_js_dir / custom_js_source.name

    updated_nav_files = list(current_nav_files)
    home_page_filename = "index.md"
    mkdocs_index_final_path = mkdocs_docs_dir / home_page_filename

    # Handle index.md (only if not already generated by Agda processing)
    if not any(f.lower() == home_page_filename.lower() for f in updated_nav_files):
        if index_md_template_source.exists():
            assets_to_copy[index_md_template_source] = mkdocs_index_final_path
            logging.info(f"Using index.md template: {index_md_template_source}")
        elif not mkdocs_index_final_path.exists(): # Create minimal only if absolutely no index.md
            logging.warning("No 'index.md' generated or templated. Creating minimal index.md.")
            mkdocs_index_final_path.parent.mkdir(parents=True, exist_ok=True) # Ensure docs dir exists
            with open(mkdocs_index_final_path, "w", encoding="utf-8") as f: f.write("# Welcome\n")

        if home_page_filename not in updated_nav_files: # Add to nav if we copied/created it
            updated_nav_files.append(home_page_filename)


    for src, dest in assets_to_copy.items():
        try:
            if dest.exists() and dest.is_file(): # avoid warning for dirs
                # potentially being overwritten by a *different* version from assets
                logging.warning(f"  Overwrite: Asset '{src.name}' being copied to '{dest.relative_to(PROJECT_ROOT)}' "
                                f"is overwriting an existing file.")
            logging.info(f"  Copying asset {src.name} to {dest.relative_to(project_root)}")
            dest.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(src, dest)
        except Exception as e: logging.error(f"Failed to copy asset {src} to {dest}: {e}")

    # Ensure unique list for nav, with index.md first.
    return sorted(
        list(set(updated_nav_files)),
        key=lambda f: (f.lower() != home_page_filename.lower(), f.lower())
    )

def generate_mkdocs_config(
    mkdocs_yml_target_path: Path, # This is MKDOCS_SRC_DIR / "mkdocs.yml"
    nav_files_from_docs_dir: List[str], # Flat list of .md files in docs/, used if nav.yml is not
    nav_yml_template_file: Path, # Path to nav.yml
    has_yaml_library: bool,
    # Dynamically determined extras that should always be added/ensured
    dynamic_extra_css: List[str],
    dynamic_extra_javascript: List[str]
) -> Path:
    logging.info(f"Updating/Finalizing {mkdocs_yml_target_path.name}...")

    mkdocs_config: Dict[str, Any] = {}

    if mkdocs_yml_target_path.exists() and has_yaml_library:
        try:
            with open(mkdocs_yml_target_path, 'r', encoding='utf-8') as f_yml:
                mkdocs_config = yaml.safe_load(f_yml) or {}
            logging.info(f"  Loaded existing {mkdocs_yml_target_path.name} as base configuration.")
        except Exception as e:
            logging.error(f"  Error loading existing {mkdocs_yml_target_path.name}: {e}. "
                          "Proceeding with minimal defaults and dynamic additions.", exc_info=True)
            mkdocs_config = {} # Reset to ensure defaults are applied
    elif not mkdocs_yml_target_path.exists():
        logging.warning(f"  Base {mkdocs_yml_target_path.name} not found (template dir likely "
                        "missing/empty or copy failed). Creating minimal config.")

    # Ensure essential keys exist if loaded config is very minimal or missing
    # These are sensible defaults if the base mkdocs.yml was missing or too sparse.
    mkdocs_config.setdefault("site_name", "Project Documentation")
    mkdocs_config.setdefault("theme", {"name": "material"})
    mkdocs_config.setdefault("use_directory_urls", False)

    current_extra_css = mkdocs_config.get("extra_css", [])
    if not isinstance(current_extra_css, list): current_extra_css = []
    for css_file in dynamic_extra_css:
        if css_file not in current_extra_css:
            current_extra_css.append(css_file)
    mkdocs_config["extra_css"] = current_extra_css

    current_extra_js = mkdocs_config.get("extra_javascript", [])
    if not isinstance(current_extra_js, list): current_extra_js = []
    for js_file in dynamic_extra_javascript:
        if js_file not in current_extra_js:
            current_extra_js.append(js_file)
    mkdocs_config["extra_javascript"] = current_extra_js

    # Default markdown extensions if none are specified in the template
    mkdocs_config.setdefault("markdown_extensions", [
        "admonition", "pymdownx.details", "pymdownx.superfences", "attr_list", "md_in_html",
        {"toc": {"permalink": True}},
        {"pymdownx.highlight": {"anchor_linenums": True, "use_pygments": True}},
        "pymdownx.emoji",
    ])

    # --- Navigation Handling ---
    nav_structure_for_yaml: Optional[List[Dict[str, Any]]] = None
    if nav_yml_template_file.exists() and has_yaml_library:
        logging.info(f"  Attempting to load navigation structure from {nav_yml_template_file.name}.")
        try:
            with open(nav_yml_template_file, 'r', encoding='utf-8') as f_nav:
                nav_data = yaml.safe_load(f_nav)
            if isinstance(nav_data, list): # Basic validation: nav should be a list
                nav_structure_for_yaml = nav_data
                logging.info(f"  Successfully loaded navigation from {nav_yml_template_file.name}.")
            elif nav_data is not None: # It loaded something, but not a list
                logging.warning(f"  Content of {nav_yml_template_file.name} is not a valid list structure for 'nav'. "
                                "Falling back to generated navigation.")
            # If nav_data is None (empty file), it will also fall through.
        except Exception as e:
            logging.warning(f"  Error loading or parsing {nav_yml_template_file.name}: {e}. "
                            "Falling back to generated navigation.", exc_info=True)
    elif nav_yml_template_file.exists() and not has_yaml_library:
        logging.warning(f"  Navigation template {nav_yml_template_file.name} found but PyYAML not installed. "
                        "Generating navigation.")

    if nav_structure_for_yaml is None: # If nav.yml not used or failed to load
        logging.info("  Generating navigation from processed files in docs/ directory.")
        nav_structure_for_yaml = build_nav_from_flat_files(nav_files_from_docs_dir)

    mkdocs_config['nav'] = nav_structure_for_yaml
    logging.info("  Set 'nav' section in configuration.")

    # Write the updated/generated mkdocs.yml
    try:
        mkdocs_yml_target_path.parent.mkdir(parents=True, exist_ok=True) # Ensure target dir exists
        if has_yaml_library:
            with open(mkdocs_yml_target_path, "w", encoding="utf-8") as f_yml:
                yaml.dump(mkdocs_config, f_yml, sort_keys=False, default_flow_style=False, allow_unicode=True, width=1000)
        else: # Fallback to JSON
            with open(mkdocs_yml_target_path, "w", encoding="utf-8") as f_yml_json:
                json.dump(mkdocs_config, f_yml_json, indent=2)
            logging.warning(f"  Generated {mkdocs_yml_target_path.name} as JSON (PyYAML not installed).")
        logging.info(f"  Successfully wrote final configuration to {mkdocs_yml_target_path.name}.")
    except Exception as e:
        logging.error(f"  Error writing {mkdocs_yml_target_path.name}: {e}", exc_info=True)

    return mkdocs_yml_target_path

def generate_mdbook_config(
    mdbook_toml_build_path: Path,      # Target: _build/mdbook/book.toml
    mdbook_summary_build_path: Path,   # Target: _build/mdbook/src/SUMMARY.md
    book_toml_template_source: Path,   # Source: PROJECT_ROOT/mdbook/book.toml
    summary_md_template_source: Path,  # Source: PROJECT_ROOT/mdbook/src/SUMMARY.md
    actual_content_files_in_build_src: List[str] # Basenames of .md files in _build/mdbook/src/
):
    """
    Ensures book.toml is in place and generates/copies SUMMARY.md for mdbook.
    """
    logging.info(f"\n--- Finalizing mdbook configuration ---")

    # --- 1. Handle book.toml ---
    logging.info(f"  Ensuring {mdbook_toml_build_path.name} is in place at "
                 f"'{mdbook_toml_build_path.relative_to(PROJECT_ROOT)}'...")
    if book_toml_template_source.exists():
        try:
            mdbook_toml_build_path.parent.mkdir(parents=True, exist_ok=True) # ensure _build/mdbook/ exists
            shutil.copy2(book_toml_template_source, mdbook_toml_build_path)
            logging.info(f"    Copied template '{book_toml_template_source.relative_to(PROJECT_ROOT)}' "
                         f"to '{mdbook_toml_build_path.relative_to(PROJECT_ROOT)}'.")
        except Exception as e:
            logging.error(f"    Failed to copy {book_toml_template_source.name}: {e}", exc_info=True)
    else:
        logging.warning(
            f"    Template book.toml '{book_toml_template_source}' not found. "
            f"'{mdbook_toml_build_path.name}' may be missing. Consider creating a default one "
            f"at {book_toml_template_source} or ensure it's created by an earlier step."
        )
    # Note: we could add logic here to dynamically modify mdbook_toml_build_path if needed,
    # e.g., adding [output.html.additional-css] if we have custom CSS files copied
    # into _build/mdbook/src/css/. For example:
    # if (MDBOOK_DOCS_DIR / "css" / "custom.css").exists():
    #     # Logic to load, update, and save TOML (e.g., using the `toml` library)
    #     logging.info("    (Placeholder: Logic to add custom.css to book.toml if needed)")

    # --- 2. Handle SUMMARY.md ---
    logging.info(f"  Processing {mdbook_summary_build_path.name} at "
                 f"'{mdbook_summary_build_path.relative_to(PROJECT_ROOT)}'...")
    mdbook_summary_build_path.parent.mkdir(parents=True, exist_ok=True) # ensure _build/mdbook/src/ exists

    if summary_md_template_source.exists():
        # Strategy 1: if static SUMMARY.md template exists in PROJECT_ROOT/mdbook/src/SUMMARY.md, use it!
        # (aligns with "Key Feature #3" for mdbook: user-provided SUMMARY.md is authoritative)
        try:
            shutil.copy2(summary_md_template_source, mdbook_summary_build_path)
            logging.info(
                f"    Copied user-provided SUMMARY.md from '{summary_md_template_source.relative_to(PROJECT_ROOT)}' "
                f"to '{mdbook_summary_build_path.relative_to(PROJECT_ROOT)}'."
            )
            # If user-provided SUMMARY.md already correctly lists all flat-named files (e.g., Ledger.Foo.md),
            # no further generation needed.  If it contains placeholders like {{CHAPTER_LIST}}, we read it,
            # generate chapter list, replace placeholder, and write it back.
            # For now, we'll assume a direct copy if exists.
        except Exception as e:
            logging.error(f"    Failed to copy user-provided {summary_md_template_source.name}: {e}", exc_info=True)
            # If copy fails, we might fall back to generating a basic one.
            # For robustness, let's fall back if the target still doesn't exist.
            if not mdbook_summary_build_path.exists():
                 generate_basic_summary_md(mdbook_summary_build_path, actual_content_files_in_build_src)

    else:
        # Strategy 2: If no static template, generate basic SUMMARY.md from actual_content_files
        logging.info(
            f"    User-provided SUMMARY.md template '{summary_md_template_source}' not found. "
            "Generating a basic SUMMARY.md from content files."
        )
        generate_basic_summary_md(mdbook_summary_build_path, actual_content_files_in_build_src)

def generate_basic_summary_md(
    mdbook_summary_build_path: Path,
    actual_content_files_in_build_src: List[str]
):
    """Helper function to generate a basic SUMMARY.md from a flat list of files."""
    summary_content = "# Summary\n\n"
    # Sort files, trying to put "Introduction.md" or "index.md" first.
    # This simple sort helps, but a more sophisticated one would be needed for a better ordering.

    def sort_key(filename):
        lower_name = filename.lower()
        if lower_name == "introduction.md" or lower_name == "index.md":
            return (0, filename) # prioritize these...
        return (1, filename)     # ...then sort alphabetically

    sorted_content_files = sorted(actual_content_files_in_build_src, key=sort_key)

    # Create a flat list. To infer hierarchy from "Ledger.Foo.md", we would need a helper
    # similar to our `build_nav_from_flat_files, but outputting mdbook SUMMARY.md syntax.
    # For now, a flat list:
    for md_filename in sorted_content_files:
        # Create a title from the filename (e.g., "Ledger.Foo" -> "Ledger Foo")
        # You might want more sophisticated title generation.
        title_parts = Path(md_filename).stem.split('.')
        title = " ".join(part.capitalize() for part in title_parts)
        summary_content += f"- [{title}](./{md_filename})\n"

    try:
        with open(mdbook_summary_build_path, 'w', encoding='utf-8') as f_summary:
            f_summary.write(summary_content)
        logging.info(f"    Generated basic '{mdbook_summary_build_path.name}'.")
    except Exception as e:
        logging.error(f"    Failed to write generated {mdbook_summary_build_path.name}: {e}", exc_info=True)



# --- Main Pipeline Logic ---
def main(run_agda_html_flag=False):
    """Orchestrates the documentation build pipeline."""
    logging.info("Starting MkDocs build process...")
    logging.info(f"Run Agda --html flag: {run_agda_html_flag}")

    # 1. Setup directories and logging.
    logging.info("Setting up build directories and logging...")
    setup_directories()
    setup_logging()

    # 1b. populate MKDOCS_SRC_DIR from static template content
    logging.info(f"Initializing {MKDOCS_SRC_DIR.name} from template source: "
                 f"{MKDOCS_STATIC_SRC_DIR.relative_to(PROJECT_ROOT)}")
    if MKDOCS_STATIC_SRC_DIR.exists():
        try:
            # Copytree will copy all contents from MKDOCS_STATIC_SRC_DIR into MKDOCS_SRC_DIR
            shutil.copytree(MKDOCS_STATIC_SRC_DIR, MKDOCS_SRC_DIR, dirs_exist_ok=True)
            logging.info(f"  Successfully copied base structure to {MKDOCS_SRC_DIR.name}.")
        except Exception as e:
            logging.error(f"  Failed to copy static template from {MKDOCS_STATIC_SRC_DIR.name} "
                          f"to {MKDOCS_SRC_DIR.name}: {e}", exc_info=True)
            # Decide if this is a fatal error. If mkdocs.yml is expected from here, it might be.
            # For now, we'll let it proceed, and later stages might fail if expected files are missing.
    else:
        logging.warning(f"  Static template directory {MKDOCS_STATIC_SRC_DIR.name} not found. "
                        f"{MKDOCS_SRC_DIR.name} may be missing essential base files like mkdocs.yml.")
        # Ensure essential subdirectories like docs/ are created if the template didn't provide them
        MKDOCS_DOCS_DIR.mkdir(parents=True, exist_ok=True)
        MKDOCS_CSS_DIR.mkdir(parents=True, exist_ok=True) # Typically docs/css
        MKDOCS_JS_DIR.mkdir(parents=True, exist_ok=True)  # Typically docs/js

    # path to mkdocs.yml that was potentially copied or needs to be created/updated
    mkdocs_yml_in_build_path = MKDOCS_SRC_DIR / "mkdocs.yml"

    # 1c. Copy ENTIRE static mdbook structure
    logging.info(f"Initializing {MDBOOK_BUILD_DIR.name} from static source: {MDBOOK_STATIC_DIR.relative_to(PROJECT_ROOT)}")
    if MDBOOK_STATIC_DIR.exists(): # MDBOOK_STATIC_DIR is PROJECT_ROOT/mdbook/
        try:
            # copy the entire static mdbook project structure.
            shutil.copytree(MDBOOK_STATIC_DIR, MDBOOK_BUILD_DIR, dirs_exist_ok=True)
            logging.info(f"  Successfully copied entire static mdbook structure to {MDBOOK_BUILD_DIR.name}.")
            # This will copy:
            # PROJECT_ROOT/mdbook/book.toml -> _build/mdbook/book.toml
            # PROJECT_ROOT/mdbook/src/* (index.md, SUMMARY.md, css/, js/) -> _build/mdbook/src/*
        except Exception as e:
            logging.error(f"  Failed to copy static template from {MDBOOK_STATIC_DIR.name} "
                          f"to {MDBOOK_BUILD_DIR.name}: {e}", exc_info=True)
    else:
        logging.warning(
            f"  Static mdbook template directory {MDBOOK_STATIC_DIR.name} not found. "
            f"{MDBOOK_BUILD_DIR.name} may be missing essential files like book.toml and SUMMARY.md.")
        # If static dir missing, we must ensure the core build dirs for mdbook still exist
        # for subsequent steps (like populating with Agda files).
        MDBOOK_DOCS_DIR.mkdir(parents=True, exist_ok=True) # _build/mdbook/src/
        # MDBOOK_CSS_DIR and MDBOOK_JS_DIR would be _build/mdbook/src/css and _build/mdbook/src/js

    mdbook_summary_in_build_path = MDBOOK_DOCS_DIR / "SUMMARY.md" # Path for generate_mdbook_config


    # 2. Get path to or generate macros.json.
    macros_json_path = macros_path(MACROS_JSON, GENERATE_MACROS_PY, MACROS_STY_PATH)

    # 3. Create Agda source snapshot
    create_agda_snapshots(SRC_DIR, AGDA_SNAPSHOT_SRC_DIR, LIB_EXTS_DIR, AGDA_SNAPSHOT_LIB_EXTS_DIR)

    # 4. Convert .agda to .lagda.md in src snapshot only
    logging.info(f"\n--- Stage 4: Converting .agda files in snapshot to .lagda.md ---")
    convert_agda_to_lagda(AGDA_SNAPSHOT_SRC_DIR, PROJECT_ROOT)

    # Clean up .agda files from src snapshot after they've been converted
    logging.info("  Cleaning up processed .agda files from snapshot...")
    for agda_file_in_snapshot in list(AGDA_SNAPSHOT_SRC_DIR.rglob("*.agda")):
        corresponding_lagda_md = agda_file_in_snapshot.with_suffix(".lagda.md")
        if corresponding_lagda_md.exists(): # If conversion produced a .lagda.md
            logging.debug(f"    Removing '{agda_file_in_snapshot.name}' as its .lagda.md now exists.")
            agda_file_in_snapshot.unlink(missing_ok=True) # missing_ok in case it was already handled

    # 5. Generate snapshot .agda-lib file
    logging.info(f"\n--- Stage 5: Generating snapshot .agda-lib file ---")
    agda_lib_deps = [
        "standard-library", "standard-library-classes", "standard-library-meta", "abstract-set-theory", "iog-prelude"
    ]
    generate_agda_lib_file(AGDA_SNAPSHOT_SRC_DIR, AGDA_SNAPSHOT_LIB_EXTS_DIR, agda_lib_deps)

    # 6. Process LaTeX-based literate .lagda files in src snapshot:
    #    Identify .lagda (LaTeX) files still in the snapshot. These are the ones that
    #    were not .lagda.md or .agda files in the original src/.
    latex_files_in_snapshot_to_process: List[Path] = sorted(list(AGDA_SNAPSHOT_SRC_DIR.rglob("*.lagda")))

    processed_info_for_latex_pipeline: List[ProcessedFileInfo] = [] # For files going through the full LaTeX pipeline

    if latex_files_in_snapshot_to_process:
        logging.info(f"\n--- Stage 6: Preparing {len(latex_files_in_snapshot_to_process)} "
                     "LaTeX .lagda files from snapshot for conversion pipeline ---")

        for lagda_tex_file_in_snapshot in latex_files_in_snapshot_to_process:
            # This file is already in the snapshot and needs the full pipeline.
            # The relative path for LagdaProcessingPaths etc. is relative to AGDA_SNAPSHOT_SRC_DIR.
            current_relative_path = lagda_tex_file_in_snapshot.relative_to(AGDA_SNAPSHOT_SRC_DIR)
            paths = LagdaProcessingPaths(current_relative_path)

            # Calculate final_flat_md_filename (as you had it)
            module_name_parts = list(current_relative_path.parent.parts)
            file_stem_for_flat_name = current_relative_path.stem # e.g., "File" from "Module/File.lagda"

            is_index_file_stem = file_stem_for_flat_name.lower() == "index"
            if not module_name_parts and is_index_file_stem: module_name_flat = "index"
            elif not module_name_parts: module_name_flat = file_stem_for_flat_name
            else:
                current_module_path_parts = list(module_name_parts)
                if not is_index_file_stem: current_module_path_parts.append(file_stem_for_flat_name)
                module_name_flat = ".".join(part for part in current_module_path_parts if part)
            final_flat_md_filename = module_name_flat + ".md"

            file_info: ProcessedFileInfo = {
                "original_path": lagda_tex_file_in_snapshot, # Input for preprocess.py is the .lagda file in the snapshot
                "temp_path": paths.temp_lagda,
                "code_blocks_json_path": paths.code_blocks_json,
                "intermediate_md_path": paths.intermediate_md,
                "snapshot_target_path": paths.snapshot_target_lagda_md, # Output .lagda.md in snapshot
                "final_flat_md_filename": final_flat_md_filename,
                "relative_path_original": current_relative_path # For postprocess to find original .lagda for deletion
            }
            processed_info_for_latex_pipeline.append(file_info)
    else:
        logging.info(f"\n--- Stage 6: No LaTeX .lagda files found in snapshot requiring conversion pipeline ---")


    # --- Stage 6a: Run preprocess.py on the identified LaTeX .lagda files ---
    # The `run_latex_preprocessing_stage` function from your modular build.py needs to be
    # adapted to take this `processed_info_for_latex_pipeline`. Its core loop would iterate this list,
    # run `preprocess.py` using `file_info["original_path"]` as input, and use other paths from `file_info`.
    # For simplicity, I'll show the loop here if `run_latex_preprocessing_stage` isn't adapted yet.

    successfully_preprocessed_info: List[ProcessedFileInfo] = []
    if processed_info_for_latex_pipeline:
        logging.info(f"\n--- Preprocessing {len(processed_info_for_latex_pipeline)} LaTeX files from snapshot ---")
        for file_info in processed_info_for_latex_pipeline:
            LagdaProcessingPaths(file_info['relative_path_original']).ensure_parent_dirs_exist()
            logging.info(f"  Preprocessing: {file_info['relative_path_original']}")
            try:
                run_command([
                    "python", str(PREPROCESS_PY),
                    str(file_info["original_path"]), # This is the .lagda file in the snapshot
                    str(macros_json_path), # Path to macros.json from macros_path()
                    str(file_info["code_blocks_json_path"])
                ], stdout_file=str(file_info["temp_path"]))
                successfully_preprocessed_info.append(file_info) # Add if preprocess succeeded
            except Exception as e:
                logging.error(f"  Error during preprocess.py for {file_info['relative_path_original']}: {e}", exc_info=True)
    # `successfully_preprocessed_info` is now the list for the next stages.

    # --- Stage 6b: Build Global Label Map ---
    labels_map_file: Optional[Path] = build_global_label_map(
        successfully_preprocessed_info, # Use only successfully preprocessed files
        MKDOCS_BUILD_DIR
    )

    # --- Stage 6c: Run pandoc+lua and postprocess.py ---
    # This uses `successfully_preprocessed_info`. `run_latex_conversion_stage` should
    # use `file_info["original_path"]` (the .lagda file in snapshot) and convert it,
    # placing the output at `file_info["snapshot_target_path"]`.
    # It should also delete file_info["original_path"] (the .lagda file) from snapshot.
    run_latex_conversion_stage(
        successfully_preprocessed_info,
        labels_map_file,
        LUA_FILTER,
        POSTPROCESS_PY,
        MKDOCS_BUILD_DIR,
        AGDA_SNAPSHOT_SRC_DIR
    )

    # 7. Collect all .lagda.md files from snapshot.
    # - .lagda.md files originally in src/ and copied/preserved.
    # - .lagda.md files converted from .agda files in src/.
    # - .lagda.md files converted from .lagda files in src/.
    # AGDA_SNAPSHOT_SRC_DIR should now only contain .lagda.md files and supporting files (like .agda-lib).
    all_snapshot_lagda_md_files: List[Path] = collect_all_literate_md_in_snapshot(AGDA_SNAPSHOT_SRC_DIR)

    # 8. populate _build/agda-docs/ staging directory
    staged_md_file_paths: List[Path] = populate_agda_docs_staging(
        run_agda_html_flag, # Your command-line argument
        all_snapshot_lagda_md_files,
        AGDA_SNAPSHOT_SRC_DIR,
        AGDA_DOCS_STAGING_DIR, # New global constant BUILD_DIR / "agda-docs"
        "Ledger.lagda.md" # Or your actual main Agda file name
    )
    # staged_flat_md_filenames_str = [p.name for p in staged_md_file_paths] # (done by copy_staging_to_site_docs)

    # 8.1: populate mkdocs site from staging
    nav_files_in_docs: List[str] = copy_staging_to_site_docs(
        AGDA_DOCS_STAGING_DIR,
        MKDOCS_DOCS_DIR, # _build/mkdocs/src/docs/
        "MkDocs"
    )

    # 9. Assemble MkDocs static assets (CSS, JS, index.md)
    MKDOCS_CSS_DIR.mkdir(parents=True, exist_ok=True)   # MKDOCS_CSS_DIR needs to exist
    MKDOCS_JS_DIR.mkdir(parents=True, exist_ok=True)    # MKDOCS_JS_DIR needs to exist
    final_nav_list: List[str] = deploy_static_mkdocs_assets(
        MKDOCS_DOCS_DIR, MKDOCS_CSS_DIR, MKDOCS_JS_DIR, run_agda_html_flag, # pass original flag
        nav_files_in_docs, # (now comes from copy_staging_to_site_docs)
        MKDOCS_STATIC_CUSTOM_CSS_SOURCE, # Path object for custom.css
        MKDOCS_STATIC_CUSTOM_JS_SOURCE,  # SOURCE: Path object for custom.js
        MKDOCS_STATIC_INDEX,
        PROJECT_ROOT
    )
    # ... (generate_mkdocs_config will use final_nav_list) ...

    dynamic_css_list_for_config = []
    if (MKDOCS_CSS_DIR / "Agda.css").exists():
        dynamic_css_list_for_config.append("css/Agda.css")
    if MKDOCS_STATIC_CUSTOM_CSS_SOURCE.exists() and (MKDOCS_CSS_DIR / MKDOCS_STATIC_CUSTOM_CSS_SOURCE.name).exists():
        dynamic_css_list_for_config.append(f"css/{MKDOCS_STATIC_CUSTOM_CSS_SOURCE.name}")

    dynamic_js_list_for_config = []
    if MKDOCS_STATIC_CUSTOM_JS_SOURCE.exists() and (MKDOCS_JS_DIR / MKDOCS_STATIC_CUSTOM_JS_SOURCE.name).exists():
        dynamic_js_list_for_config.append(f"js/{MKDOCS_STATIC_CUSTOM_JS_SOURCE.name}")

    generate_mkdocs_config(
        mkdocs_yml_in_build_path, # defined in Stage 1b
        final_nav_list,
        MKDOCS_STATIC_NAV_YML,
        HAS_YAML,
        dynamic_extra_css=dynamic_css_list_for_config,
        dynamic_extra_javascript=dynamic_js_list_for_config
    )

    # 10. Populate mdbook site from staging
    mdbook_final_content_files: List[str] = copy_staging_to_site_docs(
        AGDA_DOCS_STAGING_DIR,
        MDBOOK_DOCS_DIR, # _build/mdbook/src/
        "mdbook"
    )

    # Deploy static assets specifically for mdbook (if any beyond what's in MDBOOK_STATIC_DOCS_DIR)
    # For example, copy custom CSS/JS from MDBOOK_STATIC_CSS_DIR to MDBOOK_CSS_DIR (_build/mdbook/src/css)
    # if MDBOOK_STATIC_CUSTOM_CSS_SOURCE.exists():
    #     MDBOOK_CSS_DIR.mkdir(parents=True, exist_ok=True)
    #     shutil.copy2(MDBOOK_STATIC_CUSTOM_CSS_SOURCE, MDBOOK_CSS_DIR / MDBOOK_STATIC_CUSTOM_CSS_SOURCE.name)
    # (similar for JS)

    # Generate final SUMMARY.md and ensure book.toml for mdbook is in place
    generate_mdbook_config(
        MDBOOK_BUILD_DIR / "book.toml",  # Target: _build/mdbook/book.toml
        mdbook_summary_in_build_path,    # Target: _build/mdbook/src/SUMMARY.md
        MDBOOK_BOOK_TOML_TEMPLATE,       # Source: PROJECT_ROOT/mdbook/book.toml
        MDBOOK_SUMMARY_MD_TEMPLATE,      # Source: PROJECT_ROOT/mdbook/src/SUMMARY.md (using your var name)
        mdbook_final_content_files       # List of .md basenames in _build/mdbook/src/
    )

    # 11. Final messages and cleanup
    logging.info(f"\nBuild script finished successfully!")
    logging.info(f"Primary input for Shake/Agda (if used): {AGDA_SNAPSHOT_SRC_DIR.relative_to(PROJECT_ROOT)}")
    logging.info(f"Final source for MkDocs build/serve: {MKDOCS_SRC_DIR.relative_to(PROJECT_ROOT)}")
    logging.info(f"Full log saved to: {LOG_FILE.relative_to(PROJECT_ROOT)}")
    logging.info(f"To serve the site locally, CWD to {MKDOCS_SRC_DIR.relative_to(PROJECT_ROOT)} and run \"mkdocs serve\"")

    # Call cleanup for intermediate artifacts now that the build has succeeded
    #cleanup_intermediate_artifacts()  # << comment out if artifacts needed for debugging

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Build mkdocs site source from literate Agda files.")
    parser.add_argument(
        '--run-agda',
        action='store_true',
        help="Run the 'agda --html --html-highlight=auto' step on processed .lagda.md files."
    )
    args = parser.parse_args()

    try:
        main(run_agda_html_flag=args.run_agda)
    except SystemExit as e: # catch sys.exit() specifically if used for early exits
        logging.error(f"Build process exited prematurely with code {e.code}.")
        # We may want to cleanup here; for now, cleanup is only on successful main completion.
    except Exception as e:
        logging.exception("CRITICAL ERROR: Build failed due to an unhandled exception.")
        # no cleanup here; preserve intermediate files for debugging error.
        sys.exit(1) # ensure non-zero exit code for CI
    finally:
        # executes whether main() succeeds or fails (unless sys.exit called)
        logging.info("Build script execution finished. Shutting down logging.")
        logging.shutdown()
